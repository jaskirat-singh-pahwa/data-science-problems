{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this example code along, we will introduce the concept of \"Evaluators\"\n",
    "Evaluators behave similar to Machine Learning Algorithm Objects, but they \n",
    "are designed to take in evaluation dataframes ~ model.evaluate(test_data)\n",
    "\n",
    "Evaluators are technically still \"experimental\" according to the documentation,\n",
    "so use caution when using them for production code.\n",
    "\n",
    "'''\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"logReg\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "myData = spark.read.format(\"libsvm\").load(\"/Users/jaskiratsinghp/Desktop/Python-and-Spark-for-Big-Data-master/Spark_for_Machine_Learning/Logistic_Regression/sample_libsvm_data.txt\")\n",
    "myData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets create a Logistic Regression Model\n",
    "\n",
    "logisticRegModel = LogisticRegression()\n",
    "\n",
    "fitted_logisticReg = logisticRegModel.fit(myData)\n",
    "\n",
    "logisticReg_summary = fitted_logisticReg.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logisticReg_summary.predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[127,128,129...|[19.8534775947478...|[0.99999999761359...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-20.377398194908...|[1.41321555111056...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-27.401459284891...|[1.25804865126979...|       1.0|\n",
      "|  1.0|(692,[152,153,154...|[-18.862741612668...|[6.42710509170303...|       1.0|\n",
      "|  1.0|(692,[151,152,153...|[-20.483011833009...|[1.27157209200604...|       1.0|\n",
      "|  0.0|(692,[129,130,131...|[19.8506078990277...|[0.99999999760673...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-20.337256674833...|[1.47109814695581...|       1.0|\n",
      "|  1.0|(692,[99,100,101,...|[-19.595579753418...|[3.08850168102631...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[19.2708803215613...|[0.99999999572670...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[23.6202328360422...|[0.99999999994480...|       0.0|\n",
      "|  1.0|(692,[154,155,156...|[-24.385235147661...|[2.56818872776510...|       1.0|\n",
      "|  0.0|(692,[153,154,155...|[26.3082522490179...|[0.99999999999624...|       0.0|\n",
      "|  0.0|(692,[151,152,153...|[25.8329060318703...|[0.99999999999396...|       0.0|\n",
      "|  1.0|(692,[129,130,131...|[-19.794609139086...|[2.53110684529575...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[21.0260440948067...|[0.99999999926123...|       0.0|\n",
      "|  1.0|(692,[150,151,152...|[-22.764979942873...|[1.29806018790941...|       1.0|\n",
      "|  0.0|(692,[124,125,126...|[21.5049307193954...|[0.99999999954235...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[31.9927184226421...|[0.99999999999998...|       0.0|\n",
      "|  1.0|(692,[97,98,99,12...|[-20.521067180414...|[1.22409115616505...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-22.245377742755...|[2.18250475400332...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Lets see these columns in tabular format\n",
    "logisticReg_summary.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now to do evaluation, we need to have test_data, but we didn't split the dataset\n",
    "into train_data and test_data.\n",
    "Let's do that now;\n",
    "\n",
    "'''\n",
    "\n",
    "lr_train , lr_test = myData.randomSplit([0.7 , 0.3])\n",
    "\n",
    "finalModel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFinal = finalModel.fit(lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_and_labels = fitFinal.evaluate(lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[100,101,102...|[9.89104393135796...|[0.99994937649461...|       0.0|\n",
      "|  0.0|(692,[122,123,148...|[20.7692889692019...|[0.99999999904498...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[30.9988648094182...|[0.99999999999996...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[22.1359065604703...|[0.99999999975650...|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[23.7173834661564...|[0.99999999994991...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[13.8075060142325...|[0.99999899196435...|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[27.2634869920189...|[0.99999999999855...|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[19.4280376498931...|[0.99999999634817...|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[8.40423015093813...|[0.99977613201756...|       0.0|\n",
      "|  0.0|(692,[234,235,237...|[6.16792372291315...|[0.99790879978595...|       0.0|\n",
      "|  1.0|(692,[97,98,99,12...|[-16.895483064710...|[4.59605181235519...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-15.441341989705...|[1.96747985919079...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-20.743588879301...|[9.79882077798614...|       1.0|\n",
      "|  1.0|(692,[125,126,127...|[-21.373959904783...|[5.21683567019132...|       1.0|\n",
      "|  1.0|(692,[125,126,127...|[-19.213939263670...|[4.52368337857309...|       1.0|\n",
      "|  1.0|(692,[126,127,128...|[-31.330988940776...|[2.47243219663541...|       1.0|\n",
      "|  1.0|(692,[126,127,128...|[-20.674206670718...|[1.05028248905153...|       1.0|\n",
      "|  1.0|(692,[127,128,129...|[-29.941376669930...|[9.92259650978929...|       1.0|\n",
      "|  1.0|(692,[127,128,154...|[-14.241771084279...|[6.52945783951257...|       1.0|\n",
      "|  1.0|(692,[127,128,155...|[-23.358567344303...|[7.16973488660956...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANT:\n",
    "## Its HIGHLY RECOMMENDED to check the Documentation for the same.\n",
    "\n",
    "from pyspark.ml.evaluation import (BinaryClassificationEvaluator, \n",
    "                                   MulticlassClassificationEvaluator)\n",
    "\n",
    "myEval = BinaryClassificationEvaluator()\n",
    "\n",
    "myFinalROC = myEval.evaluate(predictions_and_labels.predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myFinalROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Lets Work on the Real Time Dataset:\n",
    "\n",
    "## **We will be working on \"classic\" Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* We will use this dataset to attempt to predict what passengers survived the \n",
    "  titanic crash based solely on passengers's features (age , cabin , children etc)\n",
    "\n",
    "* We will see some better ways to deal with categorical data through a two-step\n",
    "  process.\n",
    "\n",
    "* We will also use pipelines to set stages and build models that can be easily\n",
    "  used again.\n",
    "  \n",
    "* This data also have lot of missing information, so we will need to deal with\n",
    "  that as well.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/Users/jaskiratsinghp/Desktop/PersonalStuff/Datasets/titanic.csv\" , inferSchema = True , header = True)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets do Feature Selection\n",
    "\n",
    "myCols = df.select([\n",
    "     'Survived',\n",
    "     'Pclass',\n",
    "     'Sex',\n",
    "     'Age',\n",
    "     'SibSp',\n",
    "     'Parch',\n",
    "     'Fare',\n",
    "     'Embarked'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets deal with missing data:\n",
    "## The simplest way to deal with them is to drop them.\n",
    "\n",
    "myFinalData = myCols.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets deal with the categorical data:\n",
    "\n",
    "from pyspark.ml.feature import (VectorAssembler, \n",
    "                                VectorIndexer,\n",
    "                                OneHotEncoder,\n",
    "                                StringIndexer)\n",
    "\n",
    "'''\n",
    "The way we are going to operate working on categorical columns is:\n",
    "\n",
    "First, we are going to create a String Indexer and then we are going to\n",
    "One Hot Encode them.\n",
    "This is because the String Indexer allows you to convert every string into\n",
    "a number and then we can easily apply One Hot Encoder.\n",
    "\n",
    "'''\n",
    "\n",
    "## Lets do that for Sex column.\n",
    "genderIndexer = StringIndexer(inputCol = \"Sex\" , outputCol = \"SexIndex\")\n",
    "\n",
    "genderEncoder = OneHotEncoder(inputCol = \"SexIndex\" , outputCol = \"SexVec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, lets format Embarked column.\n",
    "embarkIndexer = StringIndexer(inputCol = \"Embarked\" , outputCol = \"EmbarkIndex\")\n",
    "\n",
    "embarkEncoder = OneHotEncoder(inputCol = \"EmbarkIndex\" , outputCol = \"EmbarkVec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets format the dataset in a way that is accepted by MLlib library.\n",
    "\n",
    "assembler = VectorAssembler(inputCols = [\"Pclass\", \"SexVec\", \"EmbarkVec\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"] , \n",
    "                            outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets create our Pipeline.\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "'''\n",
    "So what Pipeline does is, it sets stages for different steps.\n",
    "\n",
    "If you have a very complex machine learning task you will often have\n",
    "to set up a bunch of stages. \n",
    "\n",
    "'''\n",
    "\n",
    "logisticReg_titanic = LogisticRegression(featuresCol = \"features\" , labelCol = \"Survived\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets set out Pipeline.\n",
    "\n",
    "pipeline = Pipeline(stages = [genderIndexer,\n",
    "                              embarkIndexer,\n",
    "                              genderEncoder,\n",
    "                              embarkEncoder,\n",
    "                              assembler,\n",
    "                              logisticReg_titanic\n",
    "                             ])\n",
    "\n",
    "## Now this pipeline will do operations in this sequence one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets split our data in train_data and test_data\n",
    "\n",
    "train_data , test_data = myFinalData.randomSplit([0.7 , 0.3])\n",
    "\n",
    "fitModel = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets transform our test_data.\n",
    "\n",
    "results = fitModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select(\"Survived\" , \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets evaluate our model\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "myEval = BinaryClassificationEvaluator(rawPredictionCol = \"prediction\" , \n",
    "                                      labelCol = \"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7614044540229885"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC = myEval.evaluate(results)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
